# Paper-Reading
12/12/2016<br>
[From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning](https://arxiv.org/pdf/1610.03342v1.pdf)<br>
[Semi Supervised Preposition-Sense Disambiguation using Multilingual Data](https://arxiv.org/pdf/1611.08813v1.pdf)<br>


11/12/2016<br>
A Convolutional Attention Network for Extreme Summarization of Source Code<br>
Recurrent Highway Networks<br>
Hierarchical Multiscale Recurrent Neural Networks<br>
[Spatially Adaptive Computation Time for Residual Networks](https://arxiv.org/pdf/1612.02297v1.pdf)<br>
[Fast Entity Linker Toolkit for training models to link entities to KnowledgeBase (Wikipedia) in documents and queries.](https://github.com/yahoo/FEL)<br>
[Bidirectional Attention Flow](https://github.com/allenai/bi-att-flow)<br> 
[CNN/Daily Mail Reading Comprehension Task](https://github.com/danqi/rc-cnn-dailymail)<br>
[PPT. Memory and Attention](http://slides.com/smerity/quora-frontiers-of-memory-and-attention#/3)<br>
Architectural Complexity Measures of Recurrent Neural Networks<br>
On Multiplicative Integration with Recurrent Neural Networks<br>
Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations<br>

Semantic Parsing<br>
[Bootstrapping Semantic Parsers from Conversations](http://homes.cs.washington.edu/~lsz/papers/az-emnlp2011.pdf)<br>
